{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core functionality\n",
    "\n",
    "> Contains module definitions and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import torchvision.models as models\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def print_all(*args, **kwargs):\n",
    "    \"Prints all arguments passed in separate lines\"\n",
    "    for arg in args: print(arg)\n",
    "    for key in kwargs.keys(): print(f'{key} : {kwargs[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "two\n",
      "arg1 : three\n",
      "arg2 : four\n"
     ]
    }
   ],
   "source": [
    "print_all('one', 'two', arg1='three', arg2='four')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def children(m:nn.Module):\n",
    "    \"get a list of children modules of `m`\"\n",
    "    return list(m.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def recursively_apply_to_children(m, f):\n",
    "    \"Apply `f` recursively to all the children of `m`\"\n",
    "    kids = children(m)\n",
    "    if isinstance(m, nn.Module): f(m)\n",
    "    for child in kids: recursively_apply_to_children(child, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bn_to_tanh(m):\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        nf = m.num_features\n",
    "        m = TanHNorm(nf)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Layers / Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "class AdjustModule(nn.Module):\n",
    "    # TODO\n",
    "    # Adds mults and adds to any nn.Module passed\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError(\"This module has not yet been implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AdjustNormFunc(nn.Module):\n",
    "    \"Creates a BatchNorm-like module using func : x = func(x) * scale + shift\"\n",
    "    def __init__(self, nf, func=torch.tanh, name=None):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.name = name\n",
    "        self.nf = nf\n",
    "        self.scale = nn.Parameter(torch.ones (nf, 1, 1))\n",
    "        self.shift = nn.Parameter(torch.zeros(nf, 1, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.func(x)\n",
    "        return x * self.scale + self.shift\n",
    "    \n",
    "    def __str__(self):\n",
    "        if self.name:\n",
    "            return \"Adjusted \" + self.name + f'({self.nf})'\n",
    "        return \"Adjusted \" + self.func.__str__() + f'({self.nf})'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tanSigmoid(x:torch.Tensor)->torch.Tensor: return torch.sigmoid(x) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gaussian(x:torch.Tensor)->torch.Tensor: return torch.exp(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "TanHNorm = partial(AdjustNormFunc, func=torch.tanh, name='TanH')\n",
    "TanSigmoidNorm = partial(AdjustNormFunc, func=tanSigmoid, name='TanSigmoid')\n",
    "GaussianNorm = partial(AdjustNormFunc, func=gaussian, name='Gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TanHNorm(3)\n",
    "b = TanSigmoidNorm(5)\n",
    "c = GaussianNorm(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted TanH(3)\n",
      "Adjusted TanSigmoid(5)\n",
      "Adjusted Gaussian(6)\n"
     ]
    }
   ],
   "source": [
    "print_all(a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying Existing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def recursive_getattr(obj:nn.Module, name:str):\n",
    "    \"\"\" getattr for nested attributes with `.` in their names \"\"\"\n",
    "    sequence = name.split('.')\n",
    "    if len(sequence) == 0:\n",
    "        return obj\n",
    "    for attr in sequence[:-1]:\n",
    "        obj = getattr(obj, attr)\n",
    "    return getattr(obj, sequence[-1])\n",
    "\n",
    "def recursive_setattr(obj:nn.Module, name:str, new_attr):\n",
    "    \"\"\" setattr for nested attributes with `.` in their names \"\"\"\n",
    "    sequence = name.split('.')\n",
    "    for attr in sequence[:-1]:\n",
    "        obj = getattr(obj, attr)\n",
    "    setattr(obj, sequence[-1], new_attr)\n",
    "\n",
    "def recreate_network(m:nn.Module, replace_func:Callable, condition:Callable=None)->nn.Module:\n",
    "    \"\"\" modifies `m` by replacing each module that satisfies `condition` with replace_func(module) \"\"\"\n",
    "    if condition is None:\n",
    "        condition = (lambda x: not x == replace_func(x))\n",
    "    modules = list(m.named_modules())\n",
    "    if len(modules) == 1:\n",
    "        return replace_func(m)\n",
    "    for name, module in modules:\n",
    "        if condition(module):\n",
    "            new = replace_func(module)\n",
    "            recursive_setattr(m, name, new)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): Adjusted TanH(64)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): Adjusted TanH(64)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Adjusted TanH(64)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): Adjusted TanH(64)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Adjusted TanH(64)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): Adjusted TanH(128)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Adjusted TanH(128)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): Adjusted TanH(128)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): Adjusted TanH(128)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Adjusted TanH(128)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): Adjusted TanH(256)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Adjusted TanH(256)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): Adjusted TanH(256)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): Adjusted TanH(256)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Adjusted TanH(256)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): Adjusted TanH(512)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Adjusted TanH(512)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): Adjusted TanH(512)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): Adjusted TanH(512)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Adjusted TanH(512)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = models.resnet18(pretrained=False)\n",
    "recreate_network(m, bn_to_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1000])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(16, 3, 224, 224)\n",
    "m(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adjusted TanH(19)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.BatchNorm2d(19)\n",
    "recreate_network(m, bn_to_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Adjusted TanH(8)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Adjusted TanH(16)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Adjusted TanH(64)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Adjusted TanH(128)\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Adjusted TanH(16)\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Conv2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=1)\n",
       "    (1): Flatten()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = simple_cnn([3, 8, 16, 64, 128, 16, 4], bn=True)\n",
    "recreate_network(m, bn_to_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(16, 3, 30, 30)\n",
    "m(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
